1) storing the frames in memory as YUV with the U and V channels chroma sub-sampled? 
    That gives you full resolution Y (luminance) and half-resolution colour (U and V) 
    which reduces RAM requirements by 50% relative to RGB.
2) reducing the colours to <256 colours which means you can use palettised images 
    which only need 1 byte/pixel instead of 3 bytes of RGB per pixel thereby 
    reducing your storage to 1/3 of RGB?



Approach

capture a frame
convert it to palette color
instead of np-array, save color id(eg 0,1,2,3,....15 in case of nord_palette) => {

    shape = image.shape[0:2] => return width and height
    indices = image.reshape(-1,3) => reshape to have 3 channels (RGB)
    new_image = color_cube[indices[:,0],indices[:,1],indices[:,2]] => for each pixel convert color
    return new_image.reshape(shape[0],shape[1],3).astype(np.uint8) => reshape to have original dimensions

}
while converting to video, map colors backwards.